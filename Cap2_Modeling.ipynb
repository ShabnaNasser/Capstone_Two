{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbb8d44-1bac-4e67-9885-3b72c1968331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run /Users/shabnanasser/workplace/git/Capstone_Two/Cap2_Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553562d5-da28-422a-bc8d-5ba766287aad",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "In the Data Modeling section, we are going to train our standardised data with three different ML models: Logistic Regression, Decision Tree Classifier and Random Forest classifier. Also, we will check the accuracy, precision, recall and f-scores of each model and find the best performing model among them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7810b-f355-406d-b478-264710bd77af",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08759a33-516c-4ba7-84c4-0e1dc4ec3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e203a8b-f388-4da5-ab44-14be2220de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Logistic Regression: [0.85796767 0.86489607 0.84064665 0.86589595 0.82774566]\n",
      "Mean CV Score: 0.8514304022213619\n",
      "\n",
      "Evaluation Metrics for Logistic Regression:\n",
      "Accuracy: 0.9260628465804066\n",
      "Precision: 0.676056338028169\n",
      "Recall: 0.45714285714285713\n",
      "F1-Score: 0.5454545454545455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model with specified solver and maximum iterations\n",
    "logreg_model = LogisticRegression(solver='liblinear',max_iter=1000)\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the logistic regression model using 5-fold cross-validation\n",
    "\n",
    "cv_scores_logreg = cross_val_score(logreg_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Logistic Regression: {cv_scores_logreg}\")\n",
    "print(f\"Mean CV Score: {cv_scores_logreg.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the logistic regression model\n",
    "# Fit the model on the transformed training data\n",
    "logreg_model.fit(X_train_transformed, y_train)\n",
    "# Make predictions on the transformed test data\n",
    "y_pred_logreg = logreg_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate evaluation metrics for logistic regression\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "\n",
    "# Print the evaluation metrics for logistic regression\n",
    "print(\"Evaluation Metrics for Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_logreg}\")\n",
    "print(f\"Precision: {precision_logreg}\")\n",
    "print(f\"Recall: {recall_logreg}\")\n",
    "print(f\"F1-Score: {f1_logreg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afa57e-7f9c-4862-95de-514389697ddb",
   "metadata": {},
   "source": [
    "## 2) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9688ea58-9de6-44a9-b156-9a67317f8ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Decision Tree: [0.90877598 0.90877598 0.90184758 0.9017341  0.89942197]\n",
      "Mean CV Score: 0.9041111214940795\n",
      "\n",
      "Evaluation Metrics for Decision Tree:\n",
      "Accuracy: 0.8872458410351202\n",
      "Precision: 0.4247787610619469\n",
      "Recall: 0.45714285714285713\n",
      "F1-Score: 0.4403669724770642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the Decision Tree model using 5-fold cross-validation\n",
    "cv_scores_dt = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Decision Tree: {cv_scores_dt}\")\n",
    "print(f\"Mean CV Score: {cv_scores_dt.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the Decision Tree model\n",
    "# Fit the model on the training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "# Print the evaluation metrics for the Decision Tree model\n",
    "print(\"Evaluation Metrics for Decision Tree:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(f\"Precision: {precision_dt}\")\n",
    "print(f\"Recall: {recall_dt}\")\n",
    "print(f\"F1-Score: {f1_dt}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146adfd0-8539-4ed2-b0be-7534ed773e3a",
   "metadata": {},
   "source": [
    "## 3) Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca89b924-02a2-44d1-83f4-371c5f50c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Random Forest: [0.93187067 0.9295612  0.94341801 0.92716763 0.91791908]\n",
      "Mean CV Score: 0.9299873179457743\n",
      "\n",
      "Evaluation Metrics for Random Forest:\n",
      "Accuracy: 0.9214417744916821\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.38095238095238093\n",
      "F1-Score: 0.4848484848484849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the Random Forest model using 5-fold cross-validation\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Random Forest: {cv_scores_rf}\")\n",
    "print(f\"Mean CV Score: {cv_scores_rf.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the Random Forest model\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "#print  evaluation metrics for the model\n",
    "print(\"Evaluation Metrics for Random Forest:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"F1-Score: {f1_rf}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe6643-5a66-4f3c-bcc0-031e23ee4271",
   "metadata": {},
   "source": [
    "<p><div style=\"text-align: justify;\">The accuracy and f score of Logistic Regression is greater than all other model. Hence we can conclude that the best performing model among these models is Logistic Regression with an accuracy of 0.926 and F1-Score: 0.545. Also, the features InscClaimAmtReimbursed, DeductibleAmtPaid, Claim_Duration, Admitted_Days along with aggregated features and the target labels Provider and Potential Fraud lead us to find the best performing model. The idea behind adding the aggregated features based on the combinations of various features is that many parties or entities might work together to make a healthcare fraud. Thus, we need to capture interactions among them to better classify the fraudsters. Including these features is that there might be a pattern like if the sum of claim re-imb amount for a provider is very high or low then it might influence the fraud. All these features are related by each other in a way or other so we believe that those features contributed to the best performing model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafd740-b9f5-4dc0-88a9-41b096e81c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
