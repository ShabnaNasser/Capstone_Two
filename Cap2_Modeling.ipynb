{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbb8d44-1bac-4e67-9885-3b72c1968331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run /Users/shabnanasser/workplace/git/Capstone_Two/Cap2_Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553562d5-da28-422a-bc8d-5ba766287aad",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "In the Data Modeling section, we are going to train our standardised data with three different ML models: Logistic Regression, Decision Tree Classifier and Random Forest classifier. Also, we will check the accuracy, precision, recall and f-scores of each model and find the best performing model among them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7810b-f355-406d-b478-264710bd77af",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08759a33-516c-4ba7-84c4-0e1dc4ec3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e203a8b-f388-4da5-ab44-14be2220de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Logistic Regression: [0.85796767 0.86489607 0.84064665 0.86589595 0.82774566]\n",
      "Mean CV Score: 0.8514304022213619\n",
      "\n",
      "Evaluation Metrics for Logistic Regression:\n",
      "Accuracy: 0.9260628465804066\n",
      "Precision: 0.676056338028169\n",
      "Recall: 0.45714285714285713\n",
      "F1-Score: 0.5454545454545455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model with specified solver and maximum iterations\n",
    "logreg_model = LogisticRegression(solver='liblinear',max_iter=1000)\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the logistic regression model using 5-fold cross-validation\n",
    "\n",
    "cv_scores_logreg = cross_val_score(logreg_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Logistic Regression: {cv_scores_logreg}\")\n",
    "print(f\"Mean CV Score: {cv_scores_logreg.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the logistic regression model\n",
    "# Fit the model on the transformed training data\n",
    "logreg_model.fit(X_train_transformed, y_train)\n",
    "# Make predictions on the transformed test data\n",
    "y_pred_logreg = logreg_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate evaluation metrics for logistic regression\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "\n",
    "# Print the evaluation metrics for logistic regression\n",
    "print(\"Evaluation Metrics for Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_logreg}\")\n",
    "print(f\"Precision: {precision_logreg}\")\n",
    "print(f\"Recall: {recall_logreg}\")\n",
    "print(f\"F1-Score: {f1_logreg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afa57e-7f9c-4862-95de-514389697ddb",
   "metadata": {},
   "source": [
    "## 2) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9688ea58-9de6-44a9-b156-9a67317f8ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Decision Tree: [0.90069284 0.92263279 0.90877598 0.89710983 0.89364162]\n",
      "Mean CV Score: 0.9045706123429762\n",
      "\n",
      "Evaluation Metrics for Decision Tree:\n",
      "Accuracy: 0.8964879852125693\n",
      "Precision: 0.46601941747572817\n",
      "Recall: 0.45714285714285713\n",
      "F1-Score: 0.46153846153846156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the Decision Tree model using 5-fold cross-validation\n",
    "cv_scores_dt = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Decision Tree: {cv_scores_dt}\")\n",
    "print(f\"Mean CV Score: {cv_scores_dt.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the Decision Tree model\n",
    "# Fit the model on the training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "# Print the evaluation metrics for the Decision Tree model\n",
    "print(\"Evaluation Metrics for Decision Tree:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(f\"Precision: {precision_dt}\")\n",
    "print(f\"Recall: {recall_dt}\")\n",
    "print(f\"F1-Score: {f1_dt}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146adfd0-8539-4ed2-b0be-7534ed773e3a",
   "metadata": {},
   "source": [
    "## 3) Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca89b924-02a2-44d1-83f4-371c5f50c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Random Forest: [0.93187067 0.93533487 0.94341801 0.93179191 0.91791908]\n",
      "Mean CV Score: 0.9320669078481891\n",
      "\n",
      "Evaluation Metrics for Random Forest:\n",
      "Accuracy: 0.9242144177449169\n",
      "Precision: 0.7017543859649122\n",
      "Recall: 0.38095238095238093\n",
      "F1-Score: 0.49382716049382713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "# Cross-validate the Random Forest model using 5-fold cross-validation\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores for Random Forest: {cv_scores_rf}\")\n",
    "print(f\"Mean CV Score: {cv_scores_rf.mean()}\\n\")\n",
    "\n",
    "# Train and evaluate the Random Forest model\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "#print  evaluation metrics for the model\n",
    "print(\"Evaluation Metrics for Random Forest:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"F1-Score: {f1_rf}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe6643-5a66-4f3c-bcc0-031e23ee4271",
   "metadata": {},
   "source": [
    "The accuracy and f score of Logistic Regression is greater than all other model. Hence we can conclude that the best performing model among these models is Logistic Regression with an accuracy of 0.926 and F1-Score: 0.545."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60581c3-3249-4594-9e08-2a803d95248c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
